<div class="orbitron">Dataset Curation</div>
<div class="m24">
        <p>A dataset which passes for implementation is one where data structure is clean &amp; consistent, has no usage-limitations for how anything is built around it, and is rich in media if any media is involved. Priding itself in its breadth, the library is open to any kind of subject matter as long as it meets said criteria.</p>
        <p>Examples of winners include Metropolitan Museum of Art and The Smithsonian since their institutional data is well structured, their usage-restrictions are clearly stated; and even after data-pruning of media-poor records, their record counts remain in abundance. For specialty data such as Mediawiki where there may be dependencies such as Mediawiki extensions, those which pass curation are the ones where the extension(s) do not conflict with the custom-parser that is used to interpret all Mediawiki implementations.</p>
        <p>
                As already mentioned, datasets which fail curation are those that have usage-restrictions on how applications can be built. This easily excludes every commercial image API such as Pixabay and Unsplash, since they say that their data cannot be used to create a &quot;competing application&quot;. Any organization with similar policies are also excluded, such as Giant Bomb when it was still active. These commercial API's shutter due to their uselessness through their stringent policies, and the library is not risking loss of data over conservative generosity. An example of this is when Marvel API shut down their comics API on Wednesday, October 29, 2025. Their API was a peculiar case where the return data was eventually pruned to become less useful, then ultimately being shuttered entirely because it has no practical meaning in their business. Data management in such a way is not very respectable, therefore any datasets where this behavior is normalized becomes an easy case for exclusion.
        </p>
        <p class="mb">
                Content aggregation API's have been known to be excluded as media-poor datasets, since their image sources are usually low-resolution placeholders while having the true media content only be available in records found in external links. Europeana and DPLA are examples of content aggregating API's which have this issue among other things, such as poor verification of media availability and abridged meta-data.
        </p>
</div>
<div class="orbitron">Data Curation</div>
<div class="m24">
        <p>After a dataset is implemented into the library, data curation involves pruning of media-poor records. There are usually two scenarios for this; the first being records which simply have no attached media to the meta-data, and the second being records where media is in some way truncated due to copyright restrictions. With many datasets being abundant in records, pruning in any number of results against these records is not something that the user will miss or even acknowledge. Completeness is important for records pertaining to inventory such as a full checklist of toys or trading cards, but not so much for a collection of museum objects where nobody has any idea how much stuff is supposed to be there.</p>
        <p>
                Dataset pruning is handled at ingestion level whenever possible, and at query level otherwise.
        </p>
</div>